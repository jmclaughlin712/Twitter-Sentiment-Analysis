This project aims to classify sentiment of a tweet as positive, negative, or neutral. It focuses on tweets related to Apple and Google products/brands, many of which came from the South by Southwest conference. Note that the tweets did not have datetime stamps, so the exact timing of the tweets is unknown. Many of them appear to be about 10 years old, and there are no references to newer products such as Airpods.

The business application of our project is to help Apple identify what customers are complaining about and what areas Apple can improve in compared to Google. 

The original data contained about 11,000 tweets from a variety of users. The sentiment of the tweets had been labeled by a panel of users. For some tweets the users were not able to determine the emotion reflected in the tweet. The goal was to use these already labeled tweets to train a model that could classify unseen data. The majority of tweets in the dataset were either positive or neutral sentiment, with negative being a significant minority class. To address this issue we prompted ChatGPT to create over 2000 new tweets with negative sentiment, using either existing tweets in the data as input or having no input at all other than the prompt. We created a diverse set of tweets with ChatGPT, many of which featured emojis, slang, and exclamation marks as seen in the original data. 

To train our model we vectorized the words from our tweets and feature engineered new columns by counting the number of words and average word length for each tweet. We also converted emojis to text, made all words lowercase, lemmatized all words, removed stopwords, and removed punctuation (with the exception of exclamation marks and question marks, as these convey sentiment). 

After cleaning our data and splitting into test and train sets, we tested a variety of models and evaluated performance based on precision metric. The best model based on precision was XGBoost with a precision of about 95%, RMSE of about 0.95 and roc-auc score of about 0.79. The other models we tested were logistic regression, random forest, decision trees, multinomial bayes, and k-nearest neighbors. We ran a grid search across all these models to find the optimal parameters, however for the XGBoost model the optimal paramaters were the default ones. We chose precision as our performance metric because of the need to idenfity negative sentiment in order to improve our products and brand. 

Based on the word vectorization results, we created Word Clouds to identify 3 topics which were frequent complaints among Apple users but not Google users: battery, software, and price. Software updates and short battery life were common concerns. (The ChatGPT tweets were not used to identify specific words or phrases in complaints, they were only used to train the model). These are areas we recommend Apple can improve in if they want to reduce negative feedback.

The main branch of this repository contains our Python Notebook, titled 'Tweet-Analysis.ipynb', a pdf of our presentation deck titled 'presentation.pdf', and the data folder. Inside of the data folder are the original tweets, the tweets created using ChatGPT, and a data description. Our individual branches contain previous versions of the notebook. 
